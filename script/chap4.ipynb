{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4210da56",
   "metadata": {},
   "source": [
    "## 4.2 K近傍法(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 KNN\n",
    "import polars as pl\n",
    "from func import autoscaling, delete_zero_std_columns, load_data\n",
    "from sklearn.neighbors import NearestNeighbors  # k-NN\n",
    "\n",
    "k_in_knn = 5  # k-NN における k\n",
    "\n",
    "# トレーニングデータの読み込み\n",
    "x_train, index_train = load_data(\"../test_data/resin.csv\", index=\"\")\n",
    "y_train = x_train.get_column(\"property\")  # 目的変数\n",
    "x_train = x_train.drop(y_train.name)  # 説明変数\n",
    "# 予測用データの読み込み\n",
    "x_pred, index_pred = load_data(\"../test_data/resin_prediction.csv\", index=\"\")\n",
    "\n",
    "# 標準偏差が 0 の特徴量の削除\n",
    "x_train = delete_zero_std_columns(x_train)\n",
    "x_pred = x_pred.select(x_train.columns)\n",
    "\n",
    "# オートスケーリング\n",
    "autoscaled_x_train = autoscaling(x_train)\n",
    "autoscaled_x_pred = autoscaling(x_pred, x_train)\n",
    "\n",
    "# k-NN による AD(Applicability Domain: モデルの適用範囲) の構築\n",
    "\"\"\"\n",
    "ADとは、予測モデルが信頼できる範囲を示す概念.モデルの内挿・外挿とは一致しない場合がある.\n",
    "AD内のサンプルに対する予測は信頼性が高いとされる.\n",
    "内挿: Xの範囲内での予測\n",
    "外挿: Xの範囲外での予測\n",
    "AD: 単純に範囲のみでなく、ほかの方法で定義される場合もある.\n",
    "k-NN による AD では、各サンプルに対して k 個の最近傍サンプルとの距離を計算し、\n",
    "その平均距離が一定の閾値以下であれば AD 内、閾値以上であれば AD 外と判定する。\n",
    "\"\"\"\n",
    "# k-NN による AD では、トレーニングデータ x を ad_model に格納することに対応\n",
    "ad_model = NearestNeighbors(n_neighbors=k_in_knn, metric=\"euclidean\")\n",
    "ad_model.fit(autoscaled_x_train)\n",
    "\n",
    "# knn距離とインデックスが戻り値\n",
    "# k_in_knn + 1(自分自身)個を抽出\n",
    "knn_distance_train, _ = ad_model.kneighbors(autoscaled_x_train, k_in_knn + 1)\n",
    "# 自分自身との距離を削除\n",
    "knn_distance_train_wo_self = pl.DataFrame(knn_distance_train).drop(pl.first())\n",
    "# 自分以外のサンプルとの距離の平均\n",
    "mean_of_knn_distance_train = knn_distance_train_wo_self.mean_horizontal().rename(\n",
    "    \"mean_of_knn_distance\"\n",
    ")\n",
    "# トレーニングデータに対して、AD の中/外を判定しcsv出力(閾値はデータの96%)\n",
    "ad_threshold = mean_of_knn_distance_train.quantile(0.96, \"lower\")\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_train,\n",
    "        \"mean_of_knn_distance\": mean_of_knn_distance_train,\n",
    "        \"within_ad\": mean_of_knn_distance_train.le(ad_threshold),\n",
    "    }\n",
    ").write_csv(\"../output/04_02/mean_of_knn_distance_train.csv\", quote_style=\"never\")\n",
    "\n",
    "# 予測用データに対して同様の処理を行う\n",
    "knn_distance_pred, knn_index_pred = ad_model.kneighbors(autoscaled_x_pred)\n",
    "# k_in_knn 個の距離の平均\n",
    "mean_of_knn_distance_pred = (\n",
    "    pl.DataFrame(knn_distance_pred).mean_horizontal().rename(\"mean_of_knn_distance\")\n",
    ")\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_pred,\n",
    "        \"mean_of_knn_distance\": mean_of_knn_distance_pred,\n",
    "        \"within_ad\": mean_of_knn_distance_pred.le(ad_threshold),\n",
    "    }\n",
    ").write_csv(\"../output/04_02/mean_of_knn_distance_prediction.csv\", quote_style=\"never\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b84fc",
   "metadata": {},
   "source": [
    "## 4.2 OCSVM (One-Class Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "トレーニングデータにおけるサポートベクター数 :10\n",
      "トレーニングデータにおけるサポートベクターの割合 :0.5\n",
      "トレーニングデータにおける外れサンプル数 :4\n",
      "トレーニングデータにおける外れサンプルの割合 :0.2\n",
      "\n",
      "予測用データセットにおける外れサンプル数 :4757 \n",
      "予測用データセットにおける外れサンプルの割合 :0.5826800587947085\n"
     ]
    }
   ],
   "source": [
    "# 4-2 One-Class Support Vector Machine\n",
    "\n",
    "import polars as pl\n",
    "from func import autoscaling, delete_zero_std_columns, load_data\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# OCSVM における nu。\n",
    "# トレーニングデータにおけるサンプル数に対する、サポートベクターの数の下限の割合\n",
    "ocsvm_nu = 0.04\n",
    "ocsvm_gamma = 0.1  # OCSVM における gamma\n",
    "\n",
    "x_train, index_train = load_data(\"../test_data/resin.csv\", index=\"\")\n",
    "x_pred, index_pred = load_data(\"../test_data/resin_prediction.csv\", index=\"\")\n",
    "\n",
    "# データ分割\n",
    "y_train = x_train.get_column(\"property\")  # 目的変数\n",
    "x_train = x_train.drop(y_train.name)  # 説明変数\n",
    "\n",
    "# 標準偏差が 0 の特徴量の削除\n",
    "x_train = delete_zero_std_columns(x_train)\n",
    "x_pred = x_pred.select(x_train.columns)\n",
    "\n",
    "# オートスケーリング\n",
    "autoscaled_x_train = autoscaling(x_train)\n",
    "autoscaled_x_pred = autoscaling(x_pred, x_train)\n",
    "\n",
    "# OCSVM による ADの決定\n",
    "ad_model = OneClassSVM(kernel=\"rbf\", gamma=ocsvm_gamma, nu=ocsvm_nu)  # AD モデルの宣言\n",
    "ad_model.fit(autoscaled_x_train)  # モデル構築\n",
    "\n",
    "# トレーニングデータのデータ密度 (f(x) の値)を取得し、\n",
    "# ADの中/外を判定(0以上:AD内、0未満:AD外)\n",
    "data_density_train = pl.Series(ad_model.decision_function(autoscaled_x_train))\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_train,\n",
    "        \"ocsvm_data_density\": data_density_train,\n",
    "        \"within_ad_flag\": data_density_train.ge(0),\n",
    "    }\n",
    ").write_csv(\"../output/04_02/ocsvm_data_density_train.csv\", quote_style=\"never\")\n",
    "\n",
    "number_of_outliers_in_training_data = data_density_train.lt(0).sum()\n",
    "support_vector_ratio = ad_model.support_.size / x_train.height\n",
    "outlier_ratio_train = number_of_outliers_in_training_data / x_train.height\n",
    "print(\n",
    "    f\"\\nトレーニングデータにおけるサポートベクター数 :{ad_model.support_.size}\"\n",
    "    f\"\\nトレーニングデータにおけるサポートベクターの割合 :{support_vector_ratio}\"\n",
    "    f\"\\nトレーニングデータにおける外れサンプル数 :{number_of_outliers_in_training_data}\"\n",
    "    f\"\\nトレーニングデータにおける外れサンプルの割合 :{outlier_ratio_train}\"\n",
    ")\n",
    "\n",
    "# 予測用データセットも同様に処理\n",
    "data_density_prediction = pl.Series(ad_model.decision_function(autoscaled_x_pred))\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_pred,\n",
    "        \"ocsvm_data_density\": data_density_prediction,\n",
    "        \"within_ad_flag\": data_density_prediction.ge(0),\n",
    "    }\n",
    ").write_csv(\"../output/04_02/ocsvm_data_density_prediction.csv\", quote_style=\"never\")\n",
    "\n",
    "num_of_outliers_in_pred_data = data_density_prediction.lt(0).sum()\n",
    "outlier_ratio_pred = num_of_outliers_in_pred_data / x_pred.height\n",
    "print(\n",
    "    f\"\\n予測用データセットにおける外れサンプル数 :{num_of_outliers_in_pred_data}\",\n",
    "    f\"\\n予測用データセットにおける外れサンプルの割合 :{outlier_ratio_pred}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72fb67",
   "metadata": {},
   "source": [
    "## 4.2 OCSVM (One-Class Support Vector Machine) Gamma optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最適化された gamma : 0.25\n",
      "\n",
      "トレーニングデータにおけるサポートベクター数 :14\n",
      "トレーニングデータにおけるサポートベクターの割合 :0.7\n",
      "トレーニングデータにおける外れサンプル数 :6\n",
      "トレーニングデータにおける外れサンプルの割合 :0.3\n",
      "\n",
      "予測用データセットにおける外れサンプル数 :6252 \n",
      "予測用データセットにおける外れサンプルの割合 :0.7658010779029887\n"
     ]
    }
   ],
   "source": [
    "# 4.2 One-Class Support Vector Machine Gamma optimization\n",
    "\n",
    "# 4-2 One-Class Support Vector Machine\n",
    "import polars as pl\n",
    "from func import autoscaling, calc_optimal_gamma, delete_zero_std_columns, load_data\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "x_train, index_train = load_data(\"../test_data/resin.csv\", index=\"\")\n",
    "x_pred, index_pred = load_data(\"../test_data/resin_prediction.csv\", index=\"\")\n",
    "\n",
    "# データ分割\n",
    "y_train = x_train.get_column(\"property\")  # 目的変数\n",
    "x_train = x_train.drop(y_train.name)  # 説明変数\n",
    "\n",
    "# 標準偏差が 0 の特徴量の削除\n",
    "x_train = delete_zero_std_columns(x_train)\n",
    "x_pred = x_pred.select(x_train.columns)\n",
    "\n",
    "# オートスケーリング\n",
    "autoscaled_x_train = autoscaling(x_train)\n",
    "autoscaled_x_pred = autoscaling(x_pred, x_train)\n",
    "\n",
    "# グラム行列の分散最大化によるガウシアンカーネルのγの最適化\n",
    "ocsvm_gammas = 2.0 ** pl.arange(-20, 11, eager=True)  # OCSVM における gamma の候補\n",
    "optimal_gamma = calc_optimal_gamma(autoscaled_x_train, ocsvm_gammas)\n",
    "print(\"最適化された gamma :\", optimal_gamma)\n",
    "\n",
    "# OCSVM による AD\n",
    "# OCSVM における nu。\n",
    "# トレーニングデータにおけるサンプル数に対する、サポートベクターの数の下限の割合\n",
    "ocsvm_nu = 0.04\n",
    "\n",
    "# AD モデルの宣言\n",
    "ad_model = OneClassSVM(kernel=\"rbf\", gamma=optimal_gamma, nu=ocsvm_nu)\n",
    "ad_model.fit(autoscaled_x_train)  # モデル構築\n",
    "\n",
    "# トレーニングデータのデータ密度 (f(x) の値)を取得し、\n",
    "# ADの中/外を判定(0以上:AD内、0未満:AD外)\n",
    "data_density_train = pl.Series(ad_model.decision_function(autoscaled_x_train))\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_train,\n",
    "        \"ocsvm_data_density\": data_density_train,\n",
    "        \"within_ad_flag\": data_density_train.ge(0),\n",
    "    }\n",
    ").write_csv(\n",
    "    \"../output/04_02/ocsvm_gamma_optimization_data_density_train.csv\",\n",
    "    quote_style=\"never\",\n",
    ")\n",
    "\n",
    "number_of_outliers_in_training_data = data_density_train.lt(0).sum()\n",
    "support_vector_ratio = ad_model.support_.size / x_train.height\n",
    "outlier_ratio_train = number_of_outliers_in_training_data / x_train.height\n",
    "print(\n",
    "    f\"\\nトレーニングデータにおけるサポートベクター数 :{ad_model.support_.size}\"\n",
    "    f\"\\nトレーニングデータにおけるサポートベクターの割合 :{support_vector_ratio}\"\n",
    "    f\"\\nトレーニングデータにおける外れサンプル数 :{number_of_outliers_in_training_data}\"\n",
    "    f\"\\nトレーニングデータにおける外れサンプルの割合 :{outlier_ratio_train}\"\n",
    ")\n",
    "\n",
    "# 予測用データセットも同様に処理\n",
    "data_density_prediction = pl.Series(ad_model.decision_function(autoscaled_x_pred))\n",
    "pl.DataFrame(\n",
    "    {\n",
    "        \"\": index_pred,\n",
    "        \"ocsvm_data_density\": data_density_prediction,\n",
    "        \"within_ad_flag\": data_density_prediction.ge(0),\n",
    "    }\n",
    ").write_csv(\n",
    "    \"../output/04_02/ocsvm_gamma_optimization_data_density_prediction.csv\",\n",
    "    quote_style=\"never\",\n",
    ")\n",
    "\n",
    "num_of_outliers_in_pred_data = data_density_prediction.lt(0).sum()\n",
    "outlier_ratio_pred = num_of_outliers_in_pred_data / x_pred.height\n",
    "print(\n",
    "    f\"\\n予測用データセットにおける外れサンプル数 :{num_of_outliers_in_pred_data}\",\n",
    "    f\"\\n予測用データセットにおける外れサンプルの割合 :{outlier_ratio_pred}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7b361",
   "metadata": {},
   "source": [
    "## 4.3 アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各サブデータセットにおける説明変数の割合 : 0.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725acd74e9f04160b7194a8b59c957a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.3 アンサンブル学習\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from func import (\n",
    "    autoscaling,\n",
    "    delete_zero_std_columns,\n",
    "    load_data,\n",
    "    optimize_hyperparameters_by_cv,\n",
    "    rescaling,\n",
    ")\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "svr_cs = 2.0 ** pl.arange(-5, 11, eager=True)  # C の候補\n",
    "svr_epsilons = 2.0 ** pl.arange(-10, 1, eager=True)  # epsilon の候補\n",
    "svr_gammas = 2.0 ** pl.arange(-20, 11, eager=True)  # gamma の候補\n",
    "\n",
    "x_train, index_train = load_data(\"../test_data/resin.csv\", index=\"\")\n",
    "x_pred, index_pred = load_data(\"../test_data/resin_prediction.csv\", index=\"\")\n",
    "\n",
    "# データ分割\n",
    "y_train = x_train.get_column(\"property\")  # 目的変数\n",
    "x_train = x_train.drop(y_train.name)  # 説明変数\n",
    "\n",
    "# 標準偏差が 0 の特徴量の削除\n",
    "x_train = delete_zero_std_columns(x_train)\n",
    "x_pred = x_pred.select(x_train.columns)\n",
    "\n",
    "# オートスケーリング\n",
    "autoscaled_x_train = autoscaling(x_train)\n",
    "autoscaled_x_pred = autoscaling(x_pred, x_train)\n",
    "autoscaled_y = autoscaling(y_train)\n",
    "\n",
    "# 各サブデータセットで選択される説明変数の数の割合を設定。0 < x < 1\n",
    "rate_of_selected_x_variables = 0.75\n",
    "print(\"各サブデータセットにおける説明変数の割合 :\", rate_of_selected_x_variables)\n",
    "\n",
    "num_of_sub_datasets = 30  # サブデータセットの数\n",
    "selected_autoscaled_x_trains = [\n",
    "    autoscaled_x_train.select(\n",
    "        pl.Series(\"x_column\", autoscaled_x_train.columns)\n",
    "        .sample(fraction=rate_of_selected_x_variables, seed=seed, shuffle=False)\n",
    "        .to_list()\n",
    "    )\n",
    "    for seed in range(num_of_sub_datasets)\n",
    "]\n",
    "selected_x_cols_list = [\n",
    "    selected_autoscaled_x_train.columns\n",
    "    for selected_autoscaled_x_train in selected_autoscaled_x_trains\n",
    "]\n",
    "\n",
    "# クロスバリデーションの分割の設定\n",
    "fold_number = 10  # N-fold CV の N\n",
    "cv = KFold(n_splits=fold_number, random_state=9, shuffle=True)\n",
    "# サブデータセットごとにモデル構築\n",
    "sub_model_list = []\n",
    "for selected_autoscaled_x_train in tqdm(selected_autoscaled_x_trains):\n",
    "    # ハイパーパラメータC, ε, γの最適化\n",
    "    (\n",
    "        optimal_c,\n",
    "        optimal_epsilon,\n",
    "        optimal_gamma,\n",
    "    ) = optimize_hyperparameters_by_cv(\n",
    "        SVR,\n",
    "        autoscaled_x_train,\n",
    "        autoscaled_y,\n",
    "        y_train,\n",
    "        svr_cs,\n",
    "        svr_epsilons,\n",
    "        svr_gammas,\n",
    "        cv,\n",
    "        verbose=False,\n",
    "    )\n",
    "    sub_model = SVR(\n",
    "        kernel=\"rbf\",\n",
    "        C=optimal_c,\n",
    "        epsilon=optimal_epsilon,\n",
    "        gamma=optimal_gamma,\n",
    "    ).fit(selected_autoscaled_x_train, autoscaled_y)\n",
    "    sub_model_list.append(sub_model)\n",
    "\n",
    "\n",
    "# サブデータセットの説明変数の種類やサブデータセットを用いて構築されたモデルを保存\n",
    "selected_bin_path = Path(\"../output/04_03/selected_x_variables_svr_gaussian.bin\")\n",
    "sub_models_bin_path = Path(\"../output/04_03/sub_models_svr_gaussian.bin\")\n",
    "with selected_bin_path.open(\"wb\") as f:\n",
    "    pickle.dump(selected_x_cols_list, f)\n",
    "with sub_models_bin_path.open(\"wb\") as f:\n",
    "    pickle.dump(sub_model_list, f)\n",
    "\n",
    "# サブデータセットの説明変数の種類やサブデータセットを用いて構築されたモデルを読み込み\n",
    "with selected_bin_path.open(\"rb\") as f:\n",
    "    selected_x_cols_list: list[pl.Series] = pickle.load(f)  # noqa: S301\n",
    "with sub_models_bin_path.open(\"rb\") as f:\n",
    "    sub_model_list: list[SVR] = pickle.load(f)  # noqa: S301\n",
    "\n",
    "estimated_y_pred_new = pl.DataFrame()\n",
    "for i, (sub_model, selected_x_cols) in enumerate(\n",
    "    tqdm(\n",
    "        zip(sub_model_list, selected_x_cols_list, strict=True),\n",
    "        total=len(sub_model_list),\n",
    "    )\n",
    "):\n",
    "    # 説明変数の選択\n",
    "    selected_autoscaled_x_prediction = autoscaled_x_pred.select(selected_x_cols)\n",
    "    # 予測用データセットの y の推定\n",
    "    estimated_y_pred = pl.Series(sub_model.predict(selected_autoscaled_x_prediction))\n",
    "    # スケールをもとに戻します\n",
    "    estimated_y_pred_new = estimated_y_pred_new.with_columns(\n",
    "        rescaling(estimated_y_pred, y_train).rename(f\"{i}\")\n",
    "    )\n",
    "\n",
    "# 予測用データセットの推定値の平均値\n",
    "estimated_y_pred_new.select(\n",
    "    index_pred.alias(\"\"),\n",
    "    estimated_y_pred_new.mean_horizontal().alias(\"mean_of_estimated_y\"),\n",
    "    # std_horizontal()がないので代替処理\n",
    "    pl.concat_list(pl.all()).list.std().alias(\"std_of_estimated_y\"),\n",
    ").write_csv(\n",
    "    \"../output/04_03/estimated_y_prediction_ensemble_svr_gaussian.csv\",\n",
    "    quote_style=\"never\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-doe-kspub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
